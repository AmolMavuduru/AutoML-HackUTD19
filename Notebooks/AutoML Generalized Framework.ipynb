{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML Generalized Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from tpot import TPOTClassifier, TPOTRegressor\n",
    "from datacleaner import autoclean\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AutoMLEstimator(object):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        \n",
    "        self.task = kwargs['task']\n",
    "        self.speed = kwargs['speed']\n",
    "        self.test_size = kwargs['test_size']\n",
    "        if self.task == 'classification':\n",
    "            self.tpot_model = TPOTClassifier(generations=self.speed, population_size=self.speed*10, verbosity=2, n_jobs=-1)\n",
    "        else:\n",
    "            self.tpot_model = TPOTRegressor(generations=self.speed, population_size=self.speed*10, verbosity=2, n_jobs=-1)\n",
    "        \n",
    "    def preprocess_data(self, data, target_column):\n",
    "        \n",
    "        clean_data = autoclean(data)\n",
    "        X = clean_data.drop(target_column, axis=1)\n",
    "        y = clean_data[target_column]\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def split_data(self, X, y):\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=self.test_size) \n",
    "    \n",
    "    def fit_model(self):\n",
    "        \n",
    "        self.tpot_model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "    def run_automl(self, data, target_column):\n",
    "        \n",
    "        self.X, self.y = self.preprocess_data(data, target_column)\n",
    "        self.split_data(self.X, self.y)\n",
    "        self.fit_model()\n",
    "    \n",
    "    def evaluate_model(self):\n",
    "        \n",
    "        metrics = defaultdict()\n",
    "        pred = self.tpot_model.fitted_pipeline_.predict(self.X_test)\n",
    "        \n",
    "        if self.task == 'classification':\n",
    "            \n",
    "            metrics['accuracy'] = accuracy_score(pred, self.y_test)\n",
    "            metrics['precision'] = precision_score(pred, self.y_test)\n",
    "            metrics['recall'] = recall_score(pred, self.y_test)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            metrics['r2_score'] = r2_score(pred, self.y_test)\n",
    "            metrics['mean_absolute_error'] = mean_absolute_error(pred, self.y_test)\n",
    "            metrics['mean_squared_error'] = mean_squared_error(pred, self.y_test)\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target_names', 'target', 'feature_names', 'filename', 'DESCR'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['feature_names'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=data['feature_names'], data=data['data'])\n",
    "df['target'] = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.9757992249296598\n",
      "Generation 2 - Current best internal CV score: 0.9757992249296598\n",
      "Generation 3 - Current best internal CV score: 0.9757992249296598\n",
      "Generation 4 - Current best internal CV score: 0.9757992249296598\n",
      "Generation 5 - Current best internal CV score: 0.9758719541328237\n",
      "Generation 6 - Current best internal CV score: 0.9758719541328237\n",
      "Generation 7 - Current best internal CV score: 0.9780453363062058\n",
      "Generation 8 - Current best internal CV score: 0.9780453363062058\n",
      "Generation 9 - Current best internal CV score: 0.9780453363062058\n",
      "Generation 10 - Current best internal CV score: 0.9780453363062058\n",
      "\n",
      "Best pipeline: GradientBoostingClassifier(PolynomialFeatures(input_matrix, degree=2, include_bias=False, interaction_only=False), learning_rate=0.1, max_depth=5, max_features=0.15000000000000002, min_samples_leaf=10, min_samples_split=14, n_estimators=100, subsample=0.2)\n"
     ]
    }
   ],
   "source": [
    "auto_ml_model = AutoMLEstimator(task='classification', speed=10, test_size=0.2)\n",
    "auto_ml_model.run_automl(df, target_column='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'crossover_count': 2,\n",
       " 'generation': 'INVALID',\n",
       " 'internal_cv_score': 0.9320592451027234,\n",
       " 'mutation_count': 5,\n",
       " 'operator_count': 2,\n",
       " 'predecessor': ('GradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.1, GradientBoostingClassifier__max_depth=7, GradientBoostingClassifier__max_features=0.55, GradientBoostingClassifier__min_samples_leaf=14, GradientBoostingClassifier__min_samples_split=10, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=0.25)',)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(auto_ml_model.tpot_model.evaluated_individuals_.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "data = load_boston()\n",
    "df = pd.DataFrame(columns=data['feature_names'], data=data['data'])\n",
    "df['target'] = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: -12.67954508477961\n",
      "Generation 2 - Current best internal CV score: -11.848068774735953\n",
      "Generation 3 - Current best internal CV score: -11.848068774735953\n",
      "Generation 4 - Current best internal CV score: -11.848068774735953\n",
      "Generation 5 - Current best internal CV score: -11.848068774735953\n",
      "\n",
      "\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: GradientBoostingRegressor(input_matrix, alpha=0.95, learning_rate=0.1, loss=huber, max_depth=4, max_features=0.7500000000000001, min_samples_leaf=2, min_samples_split=7, n_estimators=100, subsample=0.8)\n"
     ]
    }
   ],
   "source": [
    "auto_ml_model = AutoMLEstimator(task='regression', speed=10, test_size=0.3)\n",
    "auto_ml_model.run_automl(df, target_column='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'mean_absolute_error': 2.0780182432962433,\n",
       "             'mean_squared_error': 7.262445839297437,\n",
       "             'r2_score': 0.9106636135331789})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_ml_model.evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GradientBoostingRegressor'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(auto_ml_model.tpot_model.fitted_pipeline_[0]).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "widgets": {
   "state": {
    "4140c87964644e4c874a731a30aaaa0e": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
